
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Implementing Hybrid Models and Image Features &#8212; Data Science Capstone 2022</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="CalCOFI Project" href="../calcofi/description.html" />
    <link rel="prev" title="Creating a Simple Model" href="update2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-186739861-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Capstone 2022</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../welcome.html">
   Welcome to Data Science Capstone
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Class Logistics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../class/syllabus.html">
   Course Syllabus
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../class/syllabus_readings.html">
     Readings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../class/syllabus_participation.html">
     Meetings and participation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../class/syllabus_deliverables.html">
     Deliverables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../class/syllabus_policies.html">
     Course policies
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../class/contacts.html">
   Project sponsors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../class/software-tools.html">
   Software and Tools
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../class/progress-update-guidelines.html">
   Progress update guidelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../class/progress-update-initial-post-guidelines.html">
     Initial post (due Friday 2/4)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../class/progress-update-second-post-guidelines.html">
     Second post (due Friday 3/4)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../class/progress-update-third-post-guidelines.html">
     Third post (due Friday 4/29)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../class/progress-update-posting-instructions.html">
     How to post project updates
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../class/presentation-guidelines-winter.html">
   Interim presentation guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../class/presentation-guidelines-midquarter-spring.html">
   Mid-quarter presentations
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Projects
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../allthenticate/description.html">
   Allthenticate
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../allthenticate/update1.html">
     Project Update 1 (2/4/2022)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../allthenticate/update2.html">
     Project Update 2 (3/4/2022)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../allthenticate/update3.html">
     Project Update 3 (5/2/2022)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="description.html">
   AppFolio
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="update1.html">
     Starting the Project
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="update2.html">
     Creating a Simple Model
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Implementing Hybrid Models and Image Features
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../calcofi/description.html">
   CalCOFI Project
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../calcofi/calcofi-update1.html">
     CalCOFI Initial Progress and Goal Definition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../calcofi/calcofi-update2.html">
     Progress Update and Reflection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../calcofi/calcofi-update3.html">
     The Final Stretch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../carpedata/description.html">
   carpedata
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../carpedata/update1.html">
     Update 1 - (2/4/22)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../carpedata/update2.html">
     Update 2 - (3/4/22)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../carpedata/update3.html">
     Update 3 - (4/29/22)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ccber/description.html">
   ccber
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ccber/update1.html">
     Update 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ccber/update2.html">
     Update 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../cits/description.html">
   cits
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../cits/update1.html">
     Update 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cits/update2.html">
     Update 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../cits/update3.html">
     Update 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../envent/description.html">
   ENVENT Lab
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../envent/projectupdate1.html">
     Survey Pre-Processing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../envent/projectupdate2.html">
     Update 2: Moving Towards Megapoll Assembly
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../envent/projectupdate3.html">
     Update 3: Merging Demographics and Exploring Modeling
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../eri/description.html">
   eri
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../eri/update1.html">
     Update 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../eri/update2.html">
     Update 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../eri/update3.html">
     Update 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../evidation_eric/description.html">
   evidation (Eric’s team)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../evidation_eric/update1.html">
     Evidation Health Project Update 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evidation_eric/update2.html">
     Evidation Health Project Update 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evidation_eric/update3.html">
     Evidation Health Project Update 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../evidation_julio/description.html">
   Evidation (Julio’s team)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../evidation_julio/Update2_4_22.html">
     Evidation Update (Julio’s team)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evidation_julio/Update2.html">
     Evidation Update #2 (Julio’s Team)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../evidation_julio/update3.html">
     Evidation Julio Update 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../hg_insights/description.html">
   hg_insights
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../hg_insights/HG_Update1_Feb7.html">
     Update 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../hg_insights/update%202-2.html">
     Update 2
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../nri/description.html">
   NRI
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../nri/update1.html">
     NRI Group Update 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nri/update2.html">
     Team Information
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../nri/update3.html">
     NRI Group Update 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../pwc/description.html">
   PwC
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../pwc/Update_1.html">
     Update 1: Preliminaries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pwc/Update_2.html">
     Update 2: First Dive into Compression
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../sprague/description.html">
   sprague
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../sprague/Sprague_group_update_01.html">
     Update 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sprague/Sprague_group_update_02.html">
     Update 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../sprague/Sprague_group_update_03.html">
     Update 3
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/projects/appfolio/update3.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ucsb-ds-capstone-2022/ucsb-ds-capstone-2022.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ucsb-ds-capstone-2022/ucsb-ds-capstone-2022.github.io/issues/new?title=Issue%20on%20page%20%2Fprojects/appfolio/update3.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/ucsb-ds-capstone-2022/ucsb-ds-capstone-2022.github.io/edit/main/ucsb_ds_capstone_projects_2022/projects/appfolio/update3.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Implementing Hybrid Models and Image Features
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#concise-refresher">
     Concise Refresher
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-images-for-recommendation">
     Using Images for Recommendation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-preprocessing">
     Image Preprocessing
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-transfer-learning-for-image-feature-extraction">
     Using Transfer Learning For Image Feature Extraction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-implementation">
     Image Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection">
   Feature selection
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hybrid-models">
   Hybrid Models
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-cross-network-dcn">
   Deep Cross Network (DCN)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#embedding-layer">
     Embedding Layer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-network">
     Cross Network
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep-network">
     Deep Network
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combination-layer">
     Combination layer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adding-a-pre-trained-convolutional-neural-network">
     Adding a Pre-trained Convolutional Neural Network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#looking-towards-the-future">
   Looking Towards the Future
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Implementing Hybrid Models and Image Features</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Implementing Hybrid Models and Image Features
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#concise-refresher">
     Concise Refresher
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-images-for-recommendation">
     Using Images for Recommendation
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-preprocessing">
     Image Preprocessing
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-transfer-learning-for-image-feature-extraction">
     Using Transfer Learning For Image Feature Extraction
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-implementation">
     Image Implementation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection">
   Feature selection
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hybrid-models">
   Hybrid Models
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-cross-network-dcn">
   Deep Cross Network (DCN)
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#embedding-layer">
     Embedding Layer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-network">
     Cross Network
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep-network">
     Deep Network
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combination-layer">
     Combination layer
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adding-a-pre-trained-convolutional-neural-network">
     Adding a Pre-trained Convolutional Neural Network
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#looking-towards-the-future">
   Looking Towards the Future
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="implementing-hybrid-models-and-image-features">
<h1>Implementing Hybrid Models and Image Features<a class="headerlink" href="#implementing-hybrid-models-and-image-features" title="Permalink to this headline">¶</a></h1>
<div class="section" id="concise-refresher">
<h2>Concise Refresher<a class="headerlink" href="#concise-refresher" title="Permalink to this headline">¶</a></h2>
<p>At the end of last quarter, we successfully implemented constrained adaptive priors to our Bilateral Variational Autoencoder (BiVaE) model and worked with the AppFolio CS Capstone team to deploy it onto their website. We are continuing our work to implement more features into our models in hopes of improving our recommendation accuracy.</p>
<p>Additionally, we’d like to transition to exploring other models for recommendation as opposed to just focusing on the BiVaE model. We hope to improve our ranking metrics further as well as the efficiency of our inference.</p>
</div>
<div class="section" id="using-images-for-recommendation">
<h2>Using Images for Recommendation<a class="headerlink" href="#using-images-for-recommendation" title="Permalink to this headline">¶</a></h2>
<p>Images have been shown to have vast predictive power for various tasks. When broken down, images are a 2D array of pixels, with each pixel consisting of 3 color channels (Red, Green, and Blue). Within that set of pixels lie plenty of datapoints. Let’s say an image in our data set has dimensions of 384 x 512 x 3. That yields nearly 600,000 data points in just one image. Clearly each pixel’s value does not hold the same predictive standing as an individual feature of the model, but the ensemble of pixels can open up patterns in a user’s image preferences that are difficult for humans to detect. For example, a user may have a predilection towards properties with green lawns out in front. Or perhaps user’s are drawn to photos with more vibrant color contrasts. Either way, a user’s interaction with images can be valuable in determining their preferences, and since we are lucky enough to have images associated with a majority of our properties, we hope to harness the influence that they have to offer.</p>
</div>
<div class="section" id="image-preprocessing">
<h2>Image Preprocessing<a class="headerlink" href="#image-preprocessing" title="Permalink to this headline">¶</a></h2>
<p>Working with images requires various techniques of preprocessing before being used as input to a model. We had to spend some time researching how we can utilize the information stored in images and put it into our model.</p>
<p>We first needed to map our houses with their corresponding images and then vectorize them. But because the images are different sizes and different data types, we had to figure out a way to make all the images the same sizes so it will work as a modality feature. What we decided to do was to flatten the image tensors so they were all one dimension and to pad the arrays so they are all the same size.</p>
<p>However doing this means we are forcefully making the tensors the largest possible size it could be, which in some cases could consist of 150,000 elements. This is a problem because it is computationally expensive to go through all 150,000 elements for all of the images. One way to fix this is to force each vector to be a certain size; however, by doing this, we lose some predictive power and parts of the images that might be important. We explored other ways of preprocessing our images to make them workable in our models, such as interpolation, dimension reduction techniques, and transfer learning.</p>
</div>
<div class="section" id="using-transfer-learning-for-image-feature-extraction">
<h2>Using Transfer Learning For Image Feature Extraction<a class="headerlink" href="#using-transfer-learning-for-image-feature-extraction" title="Permalink to this headline">¶</a></h2>
<p>Each image contains a large number of pixels, which when dealing with thousands of images can affect our training time or even make the model unusable. To address this issue, we investigated the idea of using image pre-processing tools to reduce the dimensions of our images to a reasonable number. A powerful tool that has been shown to extract features from images is using a large pre-trained convolutional neural net. Though there are a few different available pre-models, we ended up choosing VGG16 since it is a tried and tested option. It is not the most recently updated pretrained CNN, but it still provides excellent results. Its most evident drawback, however, is its large number of parameters which makes it a bit costly.</p>
<p><img alt="VGG16 Architecture" src="https://cdn.discordapp.com/attachments/927717200247275561/969647620916138015/unknown.png" /></p>
<p>We were able to use VGG16 to convert our images to a 4096 1D-array. After attaining the pre-processed values for each image in the dataset, we appended the respective arrays to our item features in order to run experiments with the image data. Part of our future goals include investigating other image pre-processing models. A newer set of models, like the EfficientNet model, has been shown results of a similar quality to those of previous models but with a fraction of the parameters.</p>
</div>
<div class="section" id="image-implementation">
<h2>Image Implementation<a class="headerlink" href="#image-implementation" title="Permalink to this headline">¶</a></h2>
<p>To visualize the effect of our image data, we used a visual (includes images) and non visual (does not include images) bayesian personalized ranking models with our VGG16 preprocessed data. Bayesian Personalized Ranking (BPR) is a collaborative filtering method that uses a pairwise ranking optimization framework which adopts stochastic gradient ascent as the training procedure.</p>
<p><img alt="Visual Bayesian Personalized Ranking Architecture " src="https://cdn.discordapp.com/attachments/927717200247275561/969647678919155722/unknown.png" /></p>
<p>The visual version of BPR (VBPR) uses a method that incorporates visual features extracted from a pre-trained CNN and learns an embedding kernel which linearly transforms such high-dimensional features into a much lower-dimensional (say 20 or so) ‘visual
rating’ space. This is then used in the normal matrix factorization based predictor function of BPR. The only difference between VBPR and BPR is the incorporation of images and therefore is a great way to compare the inclusion of image modality.</p>
<p><img alt="Experiment results of Visual and Non-visual Bayesian Personalized Ranking " src="https://cdn.discordapp.com/attachments/927717200247275561/969647755435847680/unknown.png" /></p>
<p>As you can see above, the VBPR model that includes images performs better than BPR on every metric. This provides proof that implementing images may be beneficial for our model.</p>
<p>Now that we have some results of images benefitting the model, we plan on setting up solid baselines with them by hyperparameter tuning. We have 3 we would like to hyperparameter tune: VBPR, BPR and another image focused recommender model called Causal Rec. We’re gonna spend some time reading up on these methods and figure out which hyperparameters to use and tune.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="feature-selection">
<h1>Feature selection<a class="headerlink" href="#feature-selection" title="Permalink to this headline">¶</a></h1>
<p>With images now added to our feature set, we have plenty of item features in our dataset to use. Including as many features as possible does not always improve recommendation accuracy, and more importantly can reduce our efficiency due to large training times. Therefore, we wanted to find which ones are the most important. Feature selection allows us to choose the best variables for our model and eliminates any redundant and unimportant variables. This increases the predictive power and efficiency of our model.</p>
<p>The method we chose to perform feature selection is a forward selection. Forward selection is an iterative, greedy algorithm that starts with no features and adds the best performing feature until all combination sizes are exhausted. For example, if there are 16 features we would go through all 16 features and select the best performing one. Then, we would test the rest of the features with our best performing feature and add on the feature that performed best. We would iterate through this process until we get the combination of all 16 features.</p>
<p>There are many features that we have to go through. The biggest challenge is that we haven’t found an automated method to perform forward feature selection for our model, so we have to manually test each feature and combination of features. This has been very time consuming, and computationally expensive. In addition, due to the timeliness of this process, we have had to compromise some of our accuracy in testing for us to get through the entire process of feature selection. We have had to reduce our dataset in half and train on only 5 epochs.</p>
<p>So far, we have been able to test all our individual features and found that ‘latitude’ and ‘longitude’ (which we treated the combination as one feature) produced the best score in the metric we are focusing on (Mean Average Precision). Next we hope to continue the forward selection process and find the best combination of features.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="hybrid-models">
<h1>Hybrid Models<a class="headerlink" href="#hybrid-models" title="Permalink to this headline">¶</a></h1>
<p>The most powerful modern recommender systems are a set of hybrid models using a combination of collaborative filtering and content based methods. Our current model, the bilateral variational autoencoder, is a hybrid model but leans more towards a collaborative filtering approach since item/user features are only used as priors. Due to this limitation, we believe greater performance can be achieved using a complete hybrid approach and fully using the power of both sparse and dense features. We decided to explore various hybrid models in Microsoft’s recommender package.</p>
<p>We first started with LightFM. The LightFM model represents users and items as linear combinations of their content features’ latent factors. The model learns embeddings or latent representations of the users and items in such a way that it encodes user preferences over items. These representations produce scores for every item for a given user; items scored highly are more likely to be interesting to the user.</p>
<p>The second model we tried was Wide and Deep.  Wide and Deep is a linear model with a wide set of crossed-column (co-occurrence) features that can memorize the feature interactions, while deep neural networks (DNN) can generalize the feature patterns through low-dimensional dense embeddings learned for the sparse features. Wide-and-deep learning jointly trains wide linear models and deep neural networks to combine the benefits of memorization and generalization for recommender systems.</p>
<p>We have run these models on a small subset of our data and they have shown promise. We hope to run them on our full dataset soon and provide strong baselines for hybrid models.</p>
<p>We also explored pytorch’s newly released Torchrec library but found it lacking documentation and examples leading to endless errors. Another package we explored was recbole but their requirement of a particular structured data was too much of a headache. Long story short, recommender system libraries need much improvement.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="deep-cross-network-dcn">
<h1>Deep Cross Network (DCN)<a class="headerlink" href="#deep-cross-network-dcn" title="Permalink to this headline">¶</a></h1>
<p>The last hybrid model we explored was a deep cross network. It was developed by Google’s research team and has shown state of the art results in various benchmarks. We believe due to its success and customizable framework that it can possibly outperform our current BiVAE model and have decided to invest our efforts into it.</p>
<p><img alt="Deep Cross Network Architecture " src="https://cdn.discordapp.com/attachments/927717200247275561/969647882317746206/unknown.png" /></p>
<div class="section" id="embedding-layer">
<h2>Embedding Layer<a class="headerlink" href="#embedding-layer" title="Permalink to this headline">¶</a></h2>
<p><img alt="Embedding Layer Vector Formula " src="https://cdn.discordapp.com/attachments/927717200247275561/969647930703228968/unknown.png" /></p>
<p>DCN considers input data with sparse and dense features. DCN employs an embedding procedure to transform these sparse features into dense vectors of real values (commonly called embedding vectors). The corresponding embedding matrix for the sparse vectors will be optimized together with other parameters in the network. The combined embedding vectors and dense features are fed as input to the DCN model.</p>
</div>
<div class="section" id="cross-network">
<h2>Cross Network<a class="headerlink" href="#cross-network" title="Permalink to this headline">¶</a></h2>
<p><img alt="Cross Layer Formula " src="https://cdn.discordapp.com/attachments/927717200247275561/969648077302550598/unknown.png" /></p>
<p>The core of DCN lies in the cross layers that create explicit feature crosses. A feature cross is a synthetic feature formed by multiplying (crossing) two or more features. Crossing combinations of features can provide predictive abilities beyond what those features can provide individually. For an 𝑙-layered cross network, the highest polynomial order is 𝑙 + 1 and the network contains all the feature crosses up to the highest order. Tensorflow has an implementation of cross layers and allows us to build our DCN.</p>
</div>
<div class="section" id="deep-network">
<h2>Deep Network<a class="headerlink" href="#deep-network" title="Permalink to this headline">¶</a></h2>
<p>The cross layers could only reproduce polynomial function classes of bounded degree; any other complex function space could only be approximated. Therefore, a deep neural network is introduced next to complement the modeling of the inherent distribution in the data.</p>
<p><img alt="Hidden Layer Formula " src="https://cdn.discordapp.com/attachments/927717200247275561/969648120080248892/unknown.png" /></p>
</div>
<div class="section" id="combination-layer">
<h2>Combination layer<a class="headerlink" href="#combination-layer" title="Permalink to this headline">¶</a></h2>
<p>The input data is in parallel to both the cross and deep networks. Their outputs are then concatenated to create the final input for the output layer. The output layer is a sigmoid fully connected dense layer and outputs our item score vector.</p>
</div>
<div class="section" id="adding-a-pre-trained-convolutional-neural-network">
<h2>Adding a Pre-trained Convolutional Neural Network<a class="headerlink" href="#adding-a-pre-trained-convolutional-neural-network" title="Permalink to this headline">¶</a></h2>
<p>With the DCN framework’s capability of parallelism, it is possible to implement additional architectures to add to the combination layer. Due to images being unusable as a normal dense feature and their success in our Visual BPR experiments, we plan to add a pre-trained convolutional network in parallel and have our images directly contribute to the item ranking scores.</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="looking-towards-the-future">
<h1>Looking Towards the Future<a class="headerlink" href="#looking-towards-the-future" title="Permalink to this headline">¶</a></h1>
<p>We would like to now outline our plans for the future. We hope to discover the most efficient and best performing pre-trained convolutional neural network for our image feature extraction. We hope to create various baselines for hybrid methods, collaborative filtering methods, and image focused models. We will decide on the best performing features to include in our final model. We will seek to create a better performing model than last quarter using DCN.  Lastly, we hope to deploy our final model into AppFolio’s Computer Science Capstone Team’s website.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./projects/appfolio"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="update2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Creating a Simple Model</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../calcofi/description.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">CalCOFI Project</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By UCSB DS Capstone Class<br/>
    
        &copy; Copyright 2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>